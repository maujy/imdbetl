{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm0000001,nm0000002,\n",
      "nm0000003,\n",
      "\n",
      "nm0000004,\n",
      "nm0000005,\n",
      "nm0000006,\n",
      "nm0000007,nm0000008,nm0000009,nm0000010,nm0000011,nm0000012,nm0000014,nm0000013,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nm0000015,nm0000016,nm0000017,nm0000018,nm0000019,\n",
      "nm0000020,\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/pymysql/cursors.py:165: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm0000021,\n",
      "nm0000022,\n",
      "nm0000023,\n",
      "nm0000024,\n",
      "nm0000025,\n",
      "nm0000026,\n",
      "nm0000027,\n",
      "nm0000028,\n",
      "nm0000029,\n",
      "nm0000030,\n",
      "nm0000031,\n",
      "nm0000032,\n",
      "nm0000033,\n",
      "nm0000034,\n",
      "nm0000035,\n",
      "nm0000036,\n",
      "nm0000037,\n",
      "nm0000038,\n",
      "nm0000039,\n",
      "nm0000040,\n",
      "nm0000041,\n",
      "nm0000042,\n",
      "nm0000043,\n",
      "nm0000044,\n",
      "nm0000045,\n",
      "nm0000046,\n",
      "nm0000047,\n",
      "nm0000048,\n",
      "nm0000049,\n",
      "nm0000050,\n",
      "nm0000051,\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import sys, traceback\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import time\n",
    "import random\n",
    "import requests \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import concurrent.futures\n",
    "\n",
    "WORKERNUM = 20\n",
    "RETRYTIME = 0.5\n",
    "\n",
    "DOMAIN = \"http://www.imdb.com\"\n",
    "NAMEFILE = \"./imdb_name_list.csv\"\n",
    "# NMBIOFILE = \"./output/imdb_nmbio_list.csv\"\n",
    "NMBIOFIELDS = ['nconst','overview','mini_bio','spouse',\n",
    "               'trademark','trivia','quotes','salary']\n",
    "\n",
    "DB_TYPE = 'mysql'\n",
    "DB_DRIVER = 'pymysql'\n",
    "DB_USER = 'user'\n",
    "DB_PASS = 'bb104t1 '\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT ='3306'\n",
    "DB_NAME = 'imdb'\n",
    "DB_TBNM = \"nmbio\"    \n",
    "db_uri = '%s+%s://%s:%s@%s:%s/%s?charset=utf8'%(DB_TYPE, DB_DRIVER, DB_USER, DB_PASS, \n",
    "                                                DB_HOST, DB_PORT, DB_NAME)\n",
    "tStart = time.time()\n",
    "engine = create_engine(db_uri)\n",
    "name_df = pd.read_csv(NAMEFILE)\n",
    "\n",
    "def get_proxy():\n",
    "    resp = requests.get(\"https://free-proxy-list.net/\")\n",
    "    iplist = bs(resp.text, \"lxml\").select_one(\".table-striped\").select(\"tbody tr\")\n",
    "    plist = [iplist[i].select(\"td\")[0].text + \":\" + iplist[i].select(\"td\")[1].text\n",
    "            for i in range(len(iplist))]\n",
    "    return plist\n",
    "# proxy = {'http':'http://203.146.217.107:8080'}\n",
    "# proxy = {'http':'http://61.7.174.176:54318'}\n",
    "\n",
    "def get_url_data(url):\n",
    "    proxies = get_proxy()\n",
    "    while True:\n",
    "        proxy = {'http':'http://' + random.choice(proxies)}\n",
    "        try:\n",
    "            return requests.get(url, proxies=proxy)\n",
    "        except:\n",
    "            time.sleep(RETRYTIME) \n",
    "            \n",
    "def create_nmbio_csv(filename, fieldnames):\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        csvfile.flush()\n",
    "\n",
    "def insert_nmbio_data(filename, fieldnames, data):\n",
    "    with open(filename, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writerow(data)\n",
    "        csvfile.flush()\n",
    "\n",
    "def worker(nconst):\n",
    "    print(nconst+\",\") \n",
    "    conn = engine.connect()\n",
    "    conn.execute(\"use \"+DB_NAME+\";\")   \n",
    "    url = DOMAIN + \"/name/\" + nconst + \"/bio\"\n",
    "    while True:\n",
    "        resp = get_url_data(url)\n",
    "        soup = bs(resp.text, 'html5lib')\n",
    "        try:\n",
    "            biography=soup.find('div', class_='jumpto').find_all('a')\n",
    "            if (biography is not None):\n",
    "                nmbio = {}\n",
    "                nmbio['nconst'] = nconst\n",
    "                for bio in biography:\n",
    "                    category = bio[\"href\"].replace(\"#\",\"\")\n",
    "                    tag = soup.find('a', attrs={'name':category}).find_next().find_next()\n",
    "                    if (tag.name == \"table\"):\n",
    "                        text = \"\"\n",
    "                        for tr in tag.find_all('tr'):\n",
    "                            k = ' '.join(tr.find_next('td').text.replace(\"\\n\",\"\").split())\n",
    "                            v = ' '.join(tr.find_next('td').find_next('td').text.replace(\"\\n\", \"\").split())\n",
    "                            text += k + \":\" +v + \",\"\n",
    "                        nmbio[category] = text\n",
    "                    elif (tag.name == \"div\"):\n",
    "                        text = \"\"\n",
    "                        while (tag.name == \"div\"):\n",
    "                            text += ' '.join(tag.text.replace(\"\\n\",\"\").split())\n",
    "                            tag = tag.find_next_sibling()\n",
    "                        nmbio[category] = text  \n",
    "                df = pd.DataFrame([nmbio], columns=NMBIOFIELDS)\n",
    "                df.to_sql(name=DB_TBNM, con=conn, if_exists=\"append\")\n",
    "                conn.close()\n",
    "            return\n",
    "        except:\n",
    "#             traceback.print_exc(file=sys.stdout)\n",
    "            time.sleep(RETRYTIME)  \n",
    "    \n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(WORKERNUM) as executor:\n",
    "#     executor.map(worker,name_df['nconst'] )\n",
    "    executor.map(worker,name_df.loc[0:50,'nconst'] )\n",
    "# worker(\"nm0000001\")\n",
    "\n",
    "tEnd = time.time()\n",
    "print(\"inputnum: %s\"%(len(name_df.loc[0:50,'nconst'])))\n",
    "print(\"workernum: %s\"%(WORKERNUM))\n",
    "print(\"time: %s\"%(tEnd-tStart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmbio_df=pd.DataFrame([nmbio])\n",
    "nmbio_df.head()\n",
    "print(nmbio_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_df = pd.read_csv(NAMEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
